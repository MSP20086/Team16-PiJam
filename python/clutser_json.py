# -*- coding: utf-8 -*-
"""Clutser_json.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fej5JBmPO4ovM4eqYhPxJamc2QOBVTE-
"""

# Install required packages (if not already installed)
!pip install -q sentence-transformers networkx scikit-learn transformers

import json
import networkx as nx
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from transformers import pipeline

# --- Dummy Data Setup ---
dummy_submissions = [
    # Cluster 1: AI in Healthcare (3 entries)
    {"student_id": "S001", "summary": "AI is revolutionizing healthcare by improving diagnostics."},
    {"student_id": "S002", "summary": "Artificial Intelligence personalizes patient treatments."},
    {"student_id": "S003", "summary": "AI algorithms help in early disease detection."},
    {"student_id": "S004", "summary": "Healthcare leverages machine learning for treatment optimization."},
    {"student_id": "S005", "summary": "Deep learning improves medical imaging clarity."},
    {"student_id": "S006", "summary": "AI-powered diagnostics speed up patient care."},
    {"student_id": "S007", "summary": "Data-driven AI transforms patient treatment strategies."},
    {"student_id": "S008", "summary": "Machine learning models predict patient outcomes."},
    {"student_id": "S009", "summary": "Predictive analytics using AI changes preventive medicine."},
    {"student_id": "S010", "summary": "Innovative AI solutions personalize healthcare services."},

    # Cluster 2: Blockchain & Security (10 entries)
    {"student_id": "S011", "summary": "Blockchain ensures secure credential verification."},
    {"student_id": "S012", "summary": "Student records are managed with blockchain."},
    {"student_id": "S013", "summary": "Blockchain enhances transparency in digital transactions."},
    {"student_id": "S014", "summary": "Decentralized blockchain systems improve data privacy."},
    {"student_id": "S015", "summary": "Blockchain mitigates fraud in financial systems."},
    {"student_id": "S016", "summary": "Tamper-proof blockchain solutions secure digital assets."},
    {"student_id": "S017", "summary": "Digital identity management benefits from blockchain."},
    {"student_id": "S018", "summary": "Blockchain is adopted for secure supply chain management."},
    {"student_id": "S019", "summary": "Transparent transactions are a key blockchain feature."},
    {"student_id": "S020", "summary": "Blockchain-based voting systems enhance election security."},

    # Cluster 3: Chatbots & NLP in Education (10 entries)
    {"student_id": "S021", "summary": "Chatbots transform student support via automation."},
    {"student_id": "S022", "summary": "Educational chatbots provide learning support."},
    {"student_id": "S023", "summary": "NLP-powered chatbots offer personalized assistance."},
    {"student_id": "S024", "summary": "Automated chat systems improve response times."},
    {"student_id": "S025", "summary": "Chatbots provide real-time feedback in education."},
    {"student_id": "S026", "summary": "Virtual assistants enhance online learning experiences."},
    {"student_id": "S027", "summary": "AI chatbots are used for tutoring support."},
    {"student_id": "S028", "summary": "Chatbots reduce teacher workload."},
    {"student_id": "S029", "summary": "Interactive chatbots streamline communication."},
    {"student_id": "S030", "summary": "Chatbots in education automate common queries."},

    # Cluster 4: Robotics & Automation (10 entries)
    {"student_id": "S031", "summary": "Robots transform manufacturing via automation."},
    {"student_id": "S032", "summary": "Industrial robots boost factory efficiency."},
    {"student_id": "S033", "summary": "Automation in robotics reduces human error."},
    {"student_id": "S034", "summary": "Collaborative robots work alongside humans."},
    {"student_id": "S035", "summary": "Robotics reshape supply chain management."},
    {"student_id": "S036", "summary": "Service robots improve customer service."},
    {"student_id": "S037", "summary": "AI-driven robots are used for warehouse automation."},
    {"student_id": "S038", "summary": "Innovative robotics lead to smarter factories."},
    {"student_id": "S039", "summary": "Robotics in agriculture optimize harvesting."},
    {"student_id": "S040", "summary": "Autonomous robots revolutionize logistics."},

    # Cluster 5: Smart Home & IoT (10 entries)
    {"student_id": "S041", "summary": "Smart home devices optimize energy use."},
    {"student_id": "S042", "summary": "IoT devices make homes safer."},
    {"student_id": "S043", "summary": "Home automation systems enhance convenience."},
    {"student_id": "S044", "summary": "AI-powered thermostats adjust settings intelligently."},
    {"student_id": "S045", "summary": "Voice assistants control smart home gadgets."},
    {"student_id": "S046", "summary": "Smart security systems detect anomalies using AI."},
    {"student_id": "S047", "summary": "Connected home devices improve energy management."},
    {"student_id": "S048", "summary": "IoT in homes enables remote monitoring."},
    {"student_id": "S049", "summary": "Smart lighting systems adapt for efficiency."},
    {"student_id": "S050", "summary": "AI-integrated smart home systems streamline routines."}
]

# Extract summaries list for embedding computation
summaries = [item["summary"] for item in dummy_submissions]

# --- Step 1: Compute Embeddings and Similarity Matrix ---
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = embedding_model.encode(summaries)
similarity_matrix = cosine_similarity(embeddings)

# --- Step 2: Build the Similarity Graph G ---
G = nx.Graph()
n = len(summaries)
for i in range(n):
    # Add each node with student_id and summary text as attributes.
    G.add_node(i, student_id=dummy_submissions[i]["student_id"], text=summaries[i])
threshold = 0.75
for i in range(n):
    for j in range(i + 1, n):
        if similarity_matrix[i, j] > threshold:
            G.add_edge(i, j, weight=similarity_matrix[i, j])



# --- Step 3: Compute Layout (x,y positions) ---
pos = nx.spring_layout(G, seed=42)
for i in G.nodes():
    G.nodes[i]['x'] = float(pos[i][0])
    G.nodes[i]['y'] = float(pos[i][1])

# --- Step 4: Determine Clusters and Generate Cluster Summaries ---
# Get connected components (clusters) with more than one node.
clusters = [comp for comp in nx.connected_components(G) if len(comp) > 1]

# Map nodes to cluster indices.
node_cluster = {}
summarizer_pipeline = pipeline("summarization", model="facebook/bart-large-cnn")
cluster_summaries = {}
for idx, comp in enumerate(clusters):
    combined_text = " ".join([G.nodes[i]['text'] for i in comp])
    # Generate a one-line summary for the cluster.
    size=len(combined_text.split())
    summary_text = summarizer_pipeline(combined_text, max_length=size+5, min_length=10, do_sample=False)[0]["summary_text"]
    for node in comp:
        node_cluster[node] = idx
    cluster_summaries[idx] = summary_text

# Assign -1 for isolated nodes.
for i in G.nodes():
    if i not in node_cluster:
        node_cluster[i] = -1

# --- Step 5: Prepare JSON Data ---

# Nodes data: include id, student_id, text, x, y, and cluster assignment.
nodes_data = []
for i in G.nodes():
    nodes_data.append({
        "id": i,
        "student_id": G.nodes[i]["student_id"],
        "text": G.nodes[i]["text"],
        "x": G.nodes[i]['x'],
        "y": G.nodes[i]['y'],
        "cluster": node_cluster[i]
    })

# Edges data: include source, target, and weight.
edges_data = []
for u, v, d in G.edges(data=True):
    edges_data.append({
        "source": u,
        "target": v,
        "weight": d["weight"]
    })

# Cluster details: for each cluster, list cluster_id, student_ids, summary, and size.
cluster_details = []
for idx, comp in enumerate(clusters):
    student_ids = [G.nodes[i]["student_id"] for i in comp]
    cluster_texts = [G.nodes[i]["text"] for i in comp]
    combined_text = " ".join(cluster_texts)
    summary_text = cluster_summaries[idx]
    cluster_details.append({
        "cluster_id": f"Cluster {idx+1}",
        "student_ids": student_ids,
        "summary": summary_text,
        "size": len(comp)
    })

# Combine all into a JSON object.
response_data = {
    "nodes": nodes_data,
    "edges": edges_data,
    "cluster_details": cluster_details
}

# For testing, print the JSON object.
# print(json.dumps(response_data, indent=2))

import matplotlib.pyplot as plt
import networkx as nx
plt.figure(figsize=(12, 10))
pos = nx.spring_layout(G, seed=42)
nx.draw_networkx_nodes(G, pos, node_size=500, node_color='skyblue')
nx.draw_networkx_edges(G, pos, width=2, alpha=0.7)
nx.draw_networkx_labels(G, pos, labels={i: i for i in G.nodes()}, font_size=10)
plt.title("Content-Based Similarity Network of 50 Submissions")
plt.axis("off")
plt.show()

print(json.dumps(response_data, indent=2, default=lambda o: float(o) if isinstance(o, np.floating) else o))